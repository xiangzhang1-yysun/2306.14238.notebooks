{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor as PoolExecutor\n",
    "executor = PoolExecutor(max_workers=10)\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed, after_log, wait_random_exponential\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {}\n",
    "tm = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17304aa1f5f44f52ae9b459c459470f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for txt in tqdm(list(Path('txt').glob('*.txt'))):\n",
    "    doi = txt.stem\n",
    "\n",
    "    # %%\n",
    "    with open(f\"txt/{doi}.txt\", 'r') as f:    # i did it manually, bite me\n",
    "        text = unicodedata.normalize('NFKD', f.read())\n",
    "\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "\n",
    "    # %%\n",
    "    chunks = []\n",
    "\n",
    "    #homo\n",
    "    while True:\n",
    "\n",
    "        #hetero\n",
    "        if len(paragraphs) == 0:\n",
    "            break\n",
    "\n",
    "        chunk = ''\n",
    "\n",
    "        #homo\n",
    "        while True:\n",
    "            \n",
    "            #hetero\n",
    "            if len(paragraphs) == 0: \n",
    "                break\n",
    "\n",
    "            tm['chunk'] = chunk\n",
    "            tm['paragraphs'] = paragraphs.copy()\n",
    "\n",
    "            paragraph = paragraphs.pop(0)\n",
    "        \n",
    "            if 'nm' not in paragraph:   # this shit works\n",
    "                continue\n",
    "\n",
    "            chunk = chunk + paragraph + '\\n'\n",
    "            \n",
    "            if len(enc.encode(paragraph))<4000 and len(enc.encode(chunk))>4000:        #tm   # allow for single very long paragraph\n",
    "                chunk = tm['chunk']\n",
    "                paragraphs = tm['paragraphs'].copy()\n",
    "                break\n",
    "\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # %%\n",
    "    v['[chunk].translate.reponse.promise'] = []\n",
    "\n",
    "    for chunk in chunks:                    # main.hs\n",
    "\n",
    "        with open('template.json') as f:\n",
    "            messages = json.load(f) + [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": chunk + \"\\n\\n\\\"Phosphor\\\",\\\"Emission peak wavelength / nm\\\"\\n\"\n",
    "            }]\n",
    "\n",
    "        promise = executor.submit(          # concurrent.future\n",
    "            retry(                          # tenacity\n",
    "                wait=wait_random_exponential(min=1, max=60), \n",
    "                stop=stop_after_attempt(6)\n",
    "            )(\n",
    "                openai.ChatCompletion.create\n",
    "            ),\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        v['[chunk].translate.reponse.promise'].append(promise)\n",
    "\n",
    "    v['[chunk].translate'] = [  # yaml\n",
    "        promise.result().choices[0]['message']['content'] \n",
    "        for promise in v['[chunk].translate.reponse.promise']\n",
    "    ]\n",
    "\n",
    "    # %%\n",
    "    with open(f\"csv/{doi}.csv\",'w') as f:\n",
    "        for translate in v['[chunk].translate']:\n",
    "            f.write(translate + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightly-forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
